<h1>Understanding Peter Hancock</h2>
Two chapters of SLPJ's "The Implementation of Functional Programming Languages" (Chapters 8 and 9) were contributed by Peter Hancock on the topic of "Polymorphic Type Checking".  Chapter 8 is an "informal" presentation of the concepts, of which the first half is an approximately intuitive description of the topic; the second half, while not formal, digs deep into the mathematical concepts of the lambda calculus.  Chapter 9 presents a fully-functional type checker built in Miranda.
<p>
While constructing the type checker in Miranda demonstrates a desire to "eat his own dog food" (and moreover, in those days was considerably easier than doing so in, say, C), it adds a certain amount to the complexity of the overall approach due to the absence of state.  In the "modern era", it would be possible to use monads to compensate for this "deficiency", but obviously when implementing in an OO language such as Java or C# this is not a challenge.
<p>
Furthermore, while it is instructive to build up from the bottom, it is (to me) more intuitive to always break a problem down from the top.  The actual section on implementing the type checker is merely the final six pages of a 43 page exposition.  For me at least, the first few times I read this chapter, I had lost the plot before I reached section 9.7.
<p>
But given the facts that it <i>is</i> an explanation of the algorithm, and it provides working code, it seems an excellent place to start from, once the complexities are unravelled.  Furthermore, in part simply because of the detail, it is probably not possible to make sense of the explanation that I will now present except in the context of his work, which is <a href='http://research.microsoft.com/en-us/um/people/simonpj/papers/slpj-book-1987/slpj-book-1987.pdf'>available for download from SLPJ's site</a>.  That being the case, the one intent I have to be meticulous in detail is to reference his work by section number everywhere I take a step.
<p>
There are a few extra wrinkles that are introduced into this approach because of my personal tinkering.  I'm not sure what effects they will have yet, and since I am attempting to explain this to myself as much as to anybody else at the moment, we'll have to see what effects they end up having.
<p>
The main one is that - based on my own PhD thesis - I have deliberately designed the Flasck type system to not be strictly algebraic types, but to accept the notion that there is a single set of values which has a "Constructor" and a set of (tagged) values.  Numbers, booleans, characters and strings are somewhat "forced" into this system at the "code" level, although they are implemented natively in JavaScript.  But, for example, <tt>Nil</tt> and <tt>Cons</tt> are considered separate entities, but the type <tt>List</tt> is "later" introduced to unify the set of values which is in either of them.  The mathematical concept of non-evaluation (&bottom;) is (has to be) included in every type, but the notion of error values (which is often associated with &bottom; is hopefully excluded, although it will frequently end up being present in the function definitions.
<p>
The introduction of cards, state, methods and actors cannot, I feel, go unnoticed by the type system, although by dint of translating almost all of this away - or else externalizing it - I cannot actually see where the impact will be.
<p>
The object-oriented convention of field access - and tagged names - that I have used for "simplicity", while it should not have any effect on the overall validity of the program (it could always be translated away) may have impacts on some of the information we need to store and check.
<p>
Given that the context of this work is the Flasck compiler, for which is the full source code is available in this repository, the "input" to the type checker is a set of function definitions grouped (basically) into scopes.  At the point at which the type checker is invoked, the following steps have all been completed:
<ul>
<li>the lines have been grouped into blocks to indicate scope, and there were no alignment errors;
<li>the individual lines have been parsed and categorized, and no syntax errors remain;
<li>the function definitions have been grouped and HSIE transformation has taken place, with no definitional errors;
<li>the methods inside a card have been converted to functions, again without error;
<li>all the definitions have been grouped into scopes, with references being bound appropriately, and all references were found
</ul>
Upon entering the type checker, we are basically provided with two sets of information: a set of symbols for which there are already well-known types (because they are builtin or because they have been previously compiled as different modules and the type information has been stored) and a set of scopes containing struct, type, card and function definitions.  Although the card state is "thought of" by developers as being mutable, from the perspective of a functional language implementation, it is simply an immutable struct for the duration of one "iteration" of the event loop.
<p>
Thus, in comparison to PH9.1, I would define a program as a pair of a map of function names to type expressions for the externals, and a scope of new definitions.  Note that this scope encompasses both the concept of a list of definitions and the concept of nested <tt>LET</tt> and <tt>LETREC</tt> definitions from nested scopes.
<p>
The first step in the algorithm (see PH8.4) is to rework this form into a set of either standalone or grouped definitions which can be individually typechecked by doing dependency analysis across the definitions.  The idea is to try and identify the dependencies between definitions so that "more free" definitions can be processed and added to our "store of knowledge" before subsequent definitions are attempted.
<p>
It will be noted from the description of a program in PH9.1 that such a program is basically a single expression with all of its dependencies resolved through the use of <tt>LET</tt> and <tt>LETREC</tt> expressions.  I propose to take the same approach in a piecemeal fashion by saying that for every function definition we will say that this is "the program" with all its dependencies introduced in these forms.  However, we will, as much as possible, have tried to already resolve these.  I'm somewhat concerned about the extent to which this is possible, because of the comment in PH8.4 about doing type checking <b>before</b> lambda lifting, which would be a process which would remove some of these mutual dependencies.  I (currently) believe that the issue here is that lifting would cause some bound-in-the-same-context lambda variables to become unbound, which would change the set of programs which would be allowed to pass (see the long discussion in PH8.5.1, particularly starting near the bottom of p152).
<p>
<h2>The TypeChecker</h2>
So, without further ado, I want to introduce the pseudo-code that I intend to use to describe my type checker:
<blockquote>
<pre>
class TypeChecker {
  ErrorResult errors;
  Map<String, TypeScheme> environment;
  VariableFactory tvFactory;
  List<Set<Function>> workToDo;
  
  void typecheck();
}
</pre>
</blockquote>
Obviously, since my implementation is intended for Java, I'm not going to stray too far from that, but since none of the code presented here is actually being run through a compiler I'm (a) not going to stick too close to the syntax; and (b) there are probably going to be errors and typos creeping in.
<p>
This presentation is to be compared to the function <tt>tc</tt> in PH9.7.  The TypeChecker will be instantiated with a set of known types and expressions that will go into the "type environment" (I think it may actually need more work than this to get the appropriate struct and type definitions where we need them, e.g. for field access).   As the typechecker proceeds, it will add to that store of knowledge.  This is equivalent to the parameter <tt>gamma</tt>.
<p id='variableFactory'>
In lieu of the (somewhat convoluted) system of a "supply of unique type variable names" (<tt>ns</tt>) necessary in a functional language, I have used a type variable factory to generate a stream of unique names as they are demanded by the type checker.
<p>
The <tt>workToDo</tt> variable is instantiated with the set of dependency-analyzed groups of function definitions, where a function is, at the very least, resolved to HSIE form before processing.  Each of these will be presented to the internal typechecking function in the same way as the expression <tt>e</tt> is used in PH9.7.
<p>
The function <tt>typecheck()</tt> is called exactly once to do all the work.  Any errors will be collected and stored in <tt>errors</tt>; no exceptions should be thrown.  The typechecker may cease functioning after the first block of function definitions which have any errors, although all the errors detected for that block will be returned.  The reason for this is simply that since any subsequent blocks may be dependent on this block, if this block fails to typecheck, those blocks will not be capable of being typechecked.  If this condition does not hold (i.e. they are independent, they just happen to be later), they should be typechecked and errors reported.
<h2 id='typeSchemes'>Type Schemes</h2>
In order to represent types, we can fairly simply store a value which is either just a type variable or is the name of a type together with its polymorphic arguments.  However, when dealing with variables inside an expression, the variables need to be associated with a <tt>type scheme</tt> for some reason.  This is described in PH9.5.  The idea (and name) seem to be basically to say that in some dimensions the type is constrained, and in others it is free.  We wish to be explicit about the ways in which it is constrained, and then to maintain a list of variables which are, specifically, free.  We will then "solve" (using unification) for those variables.
<p>
The approach is thus to have a structure of the following form:
<pre>
<blockquote>
class TypeScheme {
  List<TypeVar> schematicVars;
  Object typeExpr;
  // some method to return all the unknowns in typeExpr
  // some method to apply a substitution to just the unknowns in typeExpr
}
</blockquote>
</pre>
On pages 172 and 173 he defines two functions (unknowns_scheme and sub_scheme) which are responsible for obtaining a list of all the unknown type variables in the expression and to apply a substitution to the scheme in such a way that only the unknowns are affected.  It seems reasonable that we would want both of these methods to be defined on the type scheme.  I believe the remainder of PH9.5 (9.5.3 about association lists) can be simply replaced with the word <tt>Map</tt>.
<h2 id='phi'>PHI and Unification</h2>
It seems to me that quite a bit of time is given to explaining and working through a very mathematical version of the Unification Algorithm in Section 9.4.  When I first read this, I thought it <i>was</i> the type checking algorithm.  But, in fact, I think it is a very long-winded way of discussing the fact that it's possible to work out the solution to a system of equations one step at a time.
<p>
The use of a function <tt>phi</tt> to do all the hard work appears to be just a convenience for describing what amounts to a mapping from type variables to types.  This appears to be approximately equivalent to constructing a <tt>Map</tt> to do the same thing.  In short, <tt>phi</tt> <i>is</i> the solution to the problem of unifying a system of equations.
<p>
The unification algorithm itself seems to progress one step at a time, unifying two equations at a time.  The only places in the whole typechecking algorithm where it appears to actually be invoked is buried in function application to try and unify the types of <tt>(A->B)</tt> and <tt>C</tt> in the expression <tt>(f x)</tt>; and during the processing of letrecs where it appears to be responsible for trying to bring together a set of equations.  This is actually done by using the function <tt>unifyl</tt> (p170), which takes a list of equations and simply does a <tt>foldr</tt> over them starting with the initial value being a pre-determined "solution" or <tt>phi</tt>.
<p>
It seems reasonable to me to define such a solution to a set of equations as a new class <tt>Solution</tt>, but to keep the link to the original text, for now at least (it may disappear in a refactoring), I think I'm going to call it <tt>PhiSolution</tt>.  Each element of the solution is a "substitution" which is basically a <tt>Map.Entry</tt> from type variables to type expressions.  I think it <i>probably</i> also makes sense to put methods such as <tt>extend</tt>, <tt>unify</tt> and <tt>unifyl</tt> on the <tt>PhiSolution</tt> class.
<h2 id='application'>Type Checking Application</h2>
In section 9.7.3, PH discusses how to type check application.  This only covers the case of one variable functions, but all other cases can be reduced to this case, so it's not that big of a deal.  The basic assumption is that it is <b>already known</b> what the types of the two parts of the apply node are.  That is, it is (f x) where f :: Tf and x :: Tx.  Thus we can say that Tf = Tx -> T? and then we can unify Tf and (Tx -> T?).  There appear to be about three steps in this process.
<p>
Given that we don't actually know what the types of f and x are, the first thing to do is to apply the type checking algorithm recursively to each of them.
<p>
Assuming all of that goes well, we next apply the unification algorithm based on the existing solution phi and the types Tf and (Tx -> T?) where T? is a new type variable.
<p>
Finally, if that all goes well, we return the result of applying the substitution phi to the newly introducted type variable T?, since this is the return type, i.e. the type of the application, which is what we want.
<p>
Can we directly expand this to a multi-application scenario easily, or is it better to just break it down per application?
<p>
I think it's probably easiest to do it one step at a time, but to do it WITHIN a single block.
<p>
Finally, the way in which we store apply nodes is in <tt>Closure</tt> objects.  The closure object consists of a set of values, each of which is a variable or a constant.  One possible value for a variable is another closure, in which case that needs to be evaluated.  I'm not quite sure where that leaves us.  But hopefully it will all come out in the wash.
<h2>Unification Revisited</h2>
Above in the discussion of the function <tt>phi</tt>, we briefly touched on the unification algorithm presented in PH9.4.2.  It's time to go back and look at that in more detail.  Remember that the first page of that section dealt with the construction of <tt>phi</tt> and substitutions, which we've already dealt with.  p169 mainly deals with the helper function <tt>extend</tt>, which we'll return to in a moment.
<p>
Jumping forward to p170, the unification algorithm is presented as three cases, but the second is basically the same as the first (indeed, it calls the first with the arguments in the reversed order), while the first case seems to me to really be two separate cases.
<p>
So, this is how I read the unification algorithm.  Look at the two type expressions that come in and then:
<ul>
<li>If both are type variables, call the "extend" function (presented before in PH; discussed below);
<li>If one is a type variable and the other is a more solid type (PH cases 1b and 2) then get the current type expr associated with the type variable, apply phi to the type expression and then (attempt to) unify the two results;
<li>If both are solid type expressions, then check that they have the same "basic" type (e.g. both <tt>List</tt>) and thus by implication have the same number of type variables, and then unify the lists of type variables (using the helper method <tt>unifyl</tt>).
</ul>
<tt>unifyl</tt> is really nothing special: it just keeps repeatedly calling <tt>unify</tt> with an ever-updating function <tt>phi</tt> and the pairs of type expressions from the two lists.
The <tt>extend</tt> function (presented on p169) is used to try and bind an additional variable to the solution.  There are three basic cases for this function:
<ul>
<li>We are trying to bind the variable Tn to be the same variable Tn.  This is kind of obvious, so we do nothing.
<li>We are trying to bind the variable Tn to be an expression which contains Tn.  This is a circularity and so we report an error.
<li>In any other case, Tn == expr is a solution for one of the variables, so we add it.
</ul>